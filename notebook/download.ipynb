{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28dfa438-d29a-47df-a500-f5ac1e0c67a4",
   "metadata": {},
   "source": [
    "## Notebook (Download, Data Cleaning, Data Visualization, Modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f24ba2-4564-4d13-af6c-66fab17737ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "# Get and scrape the data\n",
    "import requests\n",
    "\n",
    "base_url = \"https://fangj.github.io/friends/\"\n",
    "\n",
    "# Get the list of episode URLs\n",
    "response = requests.get(base_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "links = [link.get('href') for link in soup.find_all('a')]\n",
    "\n",
    "# Define a function to extract the dialogs from an episode\n",
    "def extract_dialogs(episode_url):\n",
    "    response = requests.get(episode_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    lines = soup.get_text().split('\\n')\n",
    "    \n",
    "    dialogs = []\n",
    "    for line in lines:\n",
    "        if ':' in line:\n",
    "            character, dialogue = line.split(':', 1)\n",
    "            character = character.strip()\n",
    "            dialogue = dialogue.strip()\n",
    "            dialogs.append((character, dialogue))\n",
    "    return dialogs\n",
    "\n",
    "# Scrape the data and save it season-wise\n",
    "season_data = {}\n",
    "for link in links:\n",
    "    if link.startswith('season'):\n",
    "        season_str = link.split('/')[-1].split('.')[0].split('ep')[0]\n",
    "\n",
    "        # Handle edge cases\n",
    "        if '-' in season_str:\n",
    "            season_str = season_str.split('-')[0]\n",
    "        if 'outtakes' in season_str:\n",
    "            continue\n",
    "        \n",
    "        season = int(season_str)\n",
    "        if season not in season_data:\n",
    "            season_data[season] = []\n",
    "\n",
    "        episode_url = base_url + link\n",
    "        season_data[season].extend(extract_dialogs(episode_url))\n",
    "\n",
    "# Process and clean the data\n",
    "# Remove non-dialogue lines and non-main characters\n",
    "main_characters = [\"Monica\", \"Chandler\", \"Ross\", \"Rachel\", \"Phoebe\", \"Joey\"]\n",
    "\n",
    "cleaned_data = {}\n",
    "\n",
    "for season, dialogs in season_data.items():\n",
    "    cleaned_dialogs = [(character.title(), dialogue) for character, dialogue in dialogs if character.title() in main_characters]\n",
    "    cleaned_data[season] = cleaned_dialogs\n",
    "        \n",
    "# Create folders\n",
    "for num in range(1, 10):\n",
    "    !mkdir data/Season_0{num}\n",
    "!mkdir data/Season_10\n",
    "\n",
    "# Save the data in csv per season\n",
    "for season, dialogs in cleaned_data.items():\n",
    "    if len(str(season)) == 3:\n",
    "        with open(f\"data/Season_0{str(season)[0]}/Episode_{str(season)[1:4]}.csv\", \"w\", newline='', encoding='utf-8') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "            csv_writer.writerow(['Character', 'Dialogue'])\n",
    "            csv_writer.writerows(dialogs)\n",
    "    else:\n",
    "        with open(f\"data/Season_{str(season)[0:2]}/Episode_{str(season)[2:5]}.csv\", \"w\", newline='', encoding='utf-8') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "            csv_writer.writerow(['Character', 'Dialogue'])\n",
    "            csv_writer.writerows(dialogs)\n",
    "\n",
    "print('Loaded successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165744a5-3ecb-4ec7-9efc-d704143ff6aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Concatinate all csv files and clean the data\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import re\n",
    "\n",
    "data_dir = 'data'\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for season in os.listdir(data_dir):\n",
    "    season_path = os.path.join(data_dir, season)\n",
    "    for episode_file in os.listdir(season_path):\n",
    "        episode_path = os.path.join(season_path, episode_file)\n",
    "        episode_data = pd.read_csv(episode_path, names=[\"Character\", \"Dialogue\"])\n",
    "        episode_data['Season'] = int(season.split('_')[-1])\n",
    "        episode_data['Episode'] = int(episode_file.split('_')[-1].split('.')[0])\n",
    "        all_data.append(episode_data)\n",
    "        \n",
    "data = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Sort the data \n",
    "data = data.sort_values(['Season', 'Episode']).reset_index(drop=True)\n",
    "data = data[~data['Character'].str.contains('Character')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786e59d4-b7f4-4b31-ae93-a6c5f572ee12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \"not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text) \n",
    "    text = re.sub(r\"cmon\", \"come on\", text)\n",
    "    text = re.sub(r\"donot\", \"do not\", text)\n",
    "    return text\n",
    "\n",
    "data[\"Dialogue\"] = data[\"Dialogue\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e452d3-c34c-4076-84c4-f248183d2f93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.to_csv('data/friends_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381153c7-383f-4886-bffc-6303370afc9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Data Visualization\n",
    "# Character lines\n",
    "character_lines = data['Character'].value_counts()\n",
    "# Define a list of colors\n",
    "colors = [\"r\", \"purple\", \"b\", \"c\", \"m\", \"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f91b25-d81a-4206-aa4a-735f5306da61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize number of lines per character (Bar Chart)\n",
    "character_lines = data['Character'].value_counts()\n",
    "top_characters = character_lines.head(10)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(top_characters.index, top_characters, color=colors)\n",
    "plt.xlabel('characters')\n",
    "plt.ylabel('Nunber of lines')\n",
    "plt.title('Number of lines per charater')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24369066-9b89-4594-b111-a5a0938fd1ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of lines per season\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lines_per_season = data['Season'].value_counts().sort_index()\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.bar(lines_per_season.index, lines_per_season.values, color=colors)\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Nunber of lines')\n",
    "plt.title('Number of lines per season')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c4b0d7-950a-467d-88a2-c607e5b91fa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Top characters per season\n",
    "seasons = data['Season'].unique()\n",
    "character_lines = data['Character'].value_counts()\n",
    "top_characters = character_lines.head(10).index\n",
    "\n",
    "colors = [\"r\", \"purple\", \"b\", \"c\", \"m\", \"y\", \"g\", \"orange\", \"brown\"]\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "lefts = [0] * len(top_characters)\n",
    "                    \n",
    "for season, color in zip(seasons, colors):\n",
    "    season_data = data[data['Season'] == season]\n",
    "    character_lines_season = season_data[\"Character\"].value_counts()\n",
    "    top_characters_season = character_lines_season.loc[top_characters]\n",
    "    \n",
    "    plt.barh(top_characters_season.index, top_characters_season.values, left=lefts, color=color)\n",
    "    lefts = [sum(x) for x in zip(lefts, top_characters_season.values)]\n",
    "                    \n",
    "plt.xlabel('Character')\n",
    "plt.ylabel('Nunber of lines')\n",
    "plt.title('Number of lines per character in season')\n",
    "plt.legend(seasons, title='Season')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0bff5d-01d9-4858-a8d6-2063cae66f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Distribution of line lengths\n",
    "data['Line_Length'] = data['Dialogue'].apply(lambda x: len(x.split()))\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.hist(data['Line_Length'], bins=5)\n",
    "plt.xlabel('Line length (words)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of line lengths')\n",
    "plt.show()                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a097fc-5867-4f42-840d-ef89ea287def",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Average line lenth per character\n",
    "character_lines = data['Character'].value_counts()\n",
    "top_characters = character_lines.head(10).index\n",
    "data['Line_Length'] = data['Dialogue'].apply(lambda x: len(x.split()))\n",
    "character_line_length = data.groupby('Character')['Line_Length'].mean().sort_values(ascending=False)\n",
    "top_character_line_length = character_line_length.loc[top_characters]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(top_character_line_length.index, top_character_line_length.values, color=colors)\n",
    "plt.xlabel('Character')\n",
    "plt.ylabel('Average line length (words)')\n",
    "plt.title('Average line length per character')\n",
    "plt.show()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24d4217-e9f8-49c2-a4ee-8739962ee47a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sentiment analysis of dialogues\n",
    "from textblob import TextBlob\n",
    "\n",
    "def get_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    return analysis.sentiment.polarity\n",
    "\n",
    "data['Sentiment'] = data['Dialogue'].apply(get_sentiment)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(data['Sentiment'], bins=10)\n",
    "plt.xlabel('Sentiment polarity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f'Sentiment analysis of dialogues')\n",
    "plt.show()\n",
    "\n",
    "# Neutral "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2faadb-214e-46c0-8166-300385871d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f6a571-7a83-47d2-85b5-4d39cab9e323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Text Classification\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Top characters with most lines\n",
    "character_lines = data['Character'].value_counts()\n",
    "top_characters = character_lines.head(10).index\n",
    "filtered_data = data[data['Character'].isin(top_characters)]\n",
    "\n",
    "X = filtered_data['Dialogue']\n",
    "y = filtered_data['Character']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "      \n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8adfa27-5457-45d2-a47a-5de887a7bf33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "filename = \"models/text_classification_model.pkl\"\n",
    "pickle.dump(classifier, open(filename, 'wb'))\n",
    "\n",
    "vectorizer_filename = 'models/vectorizer.pkl'\n",
    "pickle.dump(vectorizer, open(vectorizer_filename, 'wb'))\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "loaded_vectorizer = pickle.load(open(vectorizer_filename, 'rb'))\n",
    "\n",
    "# Test the model\n",
    "X_text_transformed = loaded_vectorizer.transform(X_test)\n",
    "y_pred = loaded_model.predict(X_text_transformed)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy Score: {accuracy}\")\n",
    "\n",
    "# Define a new dialogue\n",
    "new_dialogue = \"We were on a break!\"\n",
    "\n",
    "new_dialogue_transformed = loaded_vectorizer.transform([new_dialogue])\n",
    "predicted_character = loaded_model.predict(new_dialogue_transformed)\n",
    "\n",
    "print(f\"The predicted character for the given dialogue is: {predicted_character[0]}\")\n",
    "\n",
    "# Get the probabilities for each class (character)\n",
    "predicted_probabilities = loaded_model.predict_proba(new_dialogue_transformed)\n",
    "max_prob_index = np.argmax(predicted_probabilities)\n",
    "max_probability = predicted_probabilities[0][max_prob_index]\n",
    "predicted_character = loaded_model.classes_[max_prob_index]\n",
    "\n",
    "print(f\"The predicted character for the given dialogue is: {predicted_character}\")\n",
    "print(f\"The confidence probability of the prediction is: {max_probability:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
